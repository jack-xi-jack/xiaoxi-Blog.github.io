<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title></title>
      <link href="/2025/03/05/1.kubeadm%E9%AB%98%E5%8F%AF%E7%94%A8%E9%83%A8%E7%BD%B2/"/>
      <url>/2025/03/05/1.kubeadm%E9%AB%98%E5%8F%AF%E7%94%A8%E9%83%A8%E7%BD%B2/</url>
      
        <content type="html"><![CDATA[<h1 id="f1b611b1"><font style="background-color:rgba(255, 255, 255, 0);">高可用架构方案</font></h1>---<h2 id="6bdfa137"><font style="background-color:rgba(255, 255, 255, 0);">高可用架构说明</font></h2>---<table><thead><tr><th><strong><font style="background-color:rgba(255, 255, 255, 0);">核心组件</font></strong></th><th><strong><font style="background-color:rgba(255, 255, 255, 0);">高可用模式</font></strong></th><th><strong><font style="background-color:rgba(255, 255, 255, 0);">高可用实现方式</font></strong></th></tr></thead><tbody><tr><td><font style="background-color:rgba(255, 255, 255, 0);">apiserver</font></td><td><font style="background-color:rgba(255, 255, 255, 0);">主备</font></td><td><font style="background-color:rgba(255, 255, 255, 0);">keepalived</font></td></tr><tr><td><font style="background-color:rgba(255, 255, 255, 0);">controller-manager</font></td><td><font style="background-color:rgba(255, 255, 255, 0);">主备</font></td><td><font style="background-color:rgba(255, 255, 255, 0);">leader election</font></td></tr><tr><td><font style="background-color:rgba(255, 255, 255, 0);">scheduler</font></td><td><font style="background-color:rgba(255, 255, 255, 0);">主备</font></td><td><font style="background-color:rgba(255, 255, 255, 0);">leader election</font></td></tr><tr><td><font style="background-color:rgba(255, 255, 255, 0);">etcd</font></td><td><font style="background-color:rgba(255, 255, 255, 0);">集群</font></td><td><font style="background-color:rgba(255, 255, 255, 0);">kubeadm</font></td></tr></tbody></table><ul><li><font style="background-color:rgba(255, 255, 255, 0);">apiserver 通过haproxy+keepalived实现高可用，当某个节点故障时触发keepalived vip 转移；</font></li><li><font style="background-color:rgba(255, 255, 255, 0);">controller-manager k8s内部通过选举方式产生领导者(由–leader-elect 选型控制，默认为true)，同一时刻集群内只有一个controller-manager组件运行；</font></li><li><font style="background-color:rgba(255, 255, 255, 0);">scheduler k8s内部通过选举方式产生领导者(由–leader-elect 选型控制，默认为true)，同一时刻集群内只有一个scheduler组件运行；</font></li><li><font style="background-color:rgba(255, 255, 255, 0);">etcd 通过运行kubeadm方式自动创建集群来实现高可用，部署的节点数为奇数。如果剩余可用节点数量超过半数，集群可以几乎没有影响的正常工作(3节点方式最多容忍一台机器宕机)</font></li></ul><h2 id="c267defc"><font style="background-color:rgba(255, 255, 255, 0);">HAProxy+</font><font style="background-color:rgba(255, 255, 255, 0);">Keepalived方案</font></h2>---<p><font style="background-color:rgba(255, 255, 255, 0);">在以前我们在私有环境下创建 Kubernetes 集群时，我们需要准备一个硬件&#x2F;软件的负载均衡器来创建多控制面集群，更多的情况下我们会选择使用 HAProxy + Keepalived 来实现这个功能。一般情况下我们会在k8s集群外创建2个负载均衡器的虚拟机，然后分配一个 VIP，然后使用 VIP 为负载均衡器提供服务，通过 VIP 将流量重定向到后端的某个 Kubernetes master节点上。</font></p><p><font style="background-color:rgba(255, 255, 255, 0);">或者在所有Kubernetes master节点上部署HAProxy + Keepalived服务，实现故障切换。</font></p><p><img src="https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738317940757-19c0d378-d69c-4d9d-bea9-19b988fceb79.jpeg"></p><h2 id="2540cb93"><font style="background-color:rgba(255, 255, 255, 0);">kube-vip方案</font></h2>---<p><font style="background-color:rgba(255, 255, 255, 0);">除了使用传统方式外，我们也可以通过kube-vip实现高可用。kube-vip 可以通过静态 pod 运行在控制平面节点上，这些 pod 通过ARP 对话来识别每个节点上的其他主机，所以需要在 hosts 文件中设置每个节点的 IP 地址，我们可以选择 BGP 或 ARP 来设置负载平衡器，这与 Metal LB 比较类似。在 ARP 模式下，会选出一个领导者，这个节点将继承虚拟 IP 并成为集群内负载均衡的 Leader，而在 BGP 模式下，所有节点都会通知 VIP 地址。</font></p><p><img src="https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738317940896-936a1802-8255-4ae3-b742-b192c9df044c.jpeg"></p><h1 id="b7a8ae3c"><font style="background-color:rgba(255, 255, 255, 0);">kube-vip 架构</font></h1>---<p><font style="background-color:rgba(255, 255, 255, 0);">kube-vip 有许多功能设计选择提供高可用性或网络功能，作为VIP&#x2F;负载平衡解决方案的一部分。</font></p><h2 id="cluster"><font style="background-color:rgba(255, 255, 255, 0);">Cluster</font></h2>---<p><font style="background-color:rgba(255, 255, 255, 0);">kube-vip 建立了一个多节点或多模块的集群来提供高可用性。在 ARP 模式下，会选出一个领导者，这个节点将继承虚拟 IP 并成为集群内负载均衡的领导者，而在 BGP 模式下，所有节点都会通知 VIP 地址。</font></p><p><font style="background-color:rgba(255, 255, 255, 0);">当使用 ARP 或 layer2 时，它将使用领导者选举，当然也可以使用 raft 集群技术，但这种方法在很大程度上已经被领导者选举所取代，特别是在集群中运行时。</font></p><h2 id="15c8be58"><font style="background-color:rgba(255, 255, 255, 0);">虚拟IP</font></h2>---<p><font style="background-color:rgba(255, 255, 255, 0);">集群中的领导者将分配 vip，并将其绑定到配置中声明的选定接口上。当领导者改变时，它将首先撤销 vip，或者在失败的情况下，vip 将直接由下一个当选的领导者分配。</font></p><p><font style="background-color:rgba(255, 255, 255, 0);">当 vip 从一个主机移动到另一个主机时，任何使用 vip 的主机将保留以前的</font><font style="background-color:rgba(255, 255, 255, 0);"> </font><font style="background-color:rgba(255, 255, 255, 0);">vip &lt;-&gt; MAC</font><font style="background-color:rgba(255, 255, 255, 0);"> </font><font style="background-color:rgba(255, 255, 255, 0);">地址映射，直到 ARP 过期（通常是30秒）并检索到一个新的</font><font style="background-color:rgba(255, 255, 255, 0);"> </font><font style="background-color:rgba(255, 255, 255, 0);">vip &lt;-&gt; MAC</font><font style="background-color:rgba(255, 255, 255, 0);"> </font><font style="background-color:rgba(255, 255, 255, 0);">映射，这可以通过使用无偿的 ARP 广播来优化。</font></p><h2 id="arp"><font style="background-color:rgba(255, 255, 255, 0);">ARP</font></h2>---<p><font style="background-color:rgba(255, 255, 255, 0);">kube-vip可以被配置为广播一个无偿的 arp（可选），通常会立即通知所有本地主机 vip &lt;-&gt; MAC 地址映射已经改变。当 ARP 广播被接收时，故障转移通常在几秒钟内完成。</font></p><h1 id="47b520ed"><font style="background-color:rgba(255, 255, 255, 0);">集群规划</font></h1>---<h2 id="2d507904"><font style="background-color:rgba(255, 255, 255, 0);">软件版本</font></h2>---<p><font style="background-color:rgba(255, 255, 255, 0);">操作系统版本：Rocky Linux release 8.8</font></p><p><font style="background-color:rgba(255, 255, 255, 0);">内核版本：4.18.0-477.21.1.el8_8.x86_64</font></p><p><font style="background-color:rgba(255, 255, 255, 0);">kubernetes版本：1.27.6</font></p><p><font style="background-color:rgba(255, 255, 255, 0);">containerd版本：1.6.22</font></p><p><font style="background-color:rgba(255, 255, 255, 0);">kube-vip版本：0.6.0</font></p><h2 id="c5b040c2"><font style="background-color:rgba(255, 255, 255, 0);">主机IP规划</font></h2>| **<font style="background-color:rgba(255, 255, 255, 0);">主机名</font>** | **<font style="background-color:rgba(255, 255, 255, 0);">ip</font>** | **<font style="background-color:rgba(255, 255, 255, 0);">主机配置</font>** | **<font style="background-color:rgba(255, 255, 255, 0);">用途</font>** || --- | --- | --- | --- || <font style="background-color:rgba(255, 255, 255, 0);">master1</font> | <font style="background-color:rgba(255, 255, 255, 0);">192.168.10.151</font> | <font style="background-color:rgba(255, 255, 255, 0);">2C2G</font> | <font style="background-color:rgba(255, 255, 255, 0);">control-plane</font> || <font style="background-color:rgba(255, 255, 255, 0);">master2</font> | <font style="background-color:rgba(255, 255, 255, 0);">192.168.10.152</font> | <font style="background-color:rgba(255, 255, 255, 0);">2C2G</font> | <font style="background-color:rgba(255, 255, 255, 0);">control-plane</font> || <font style="background-color:rgba(255, 255, 255, 0);">master3</font> | <font style="background-color:rgba(255, 255, 255, 0);">192.168.10.153</font> | <font style="background-color:rgba(255, 255, 255, 0);">2C2G</font> | <font style="background-color:rgba(255, 255, 255, 0);">control-plane</font> || <font style="background-color:rgba(255, 255, 255, 0);">work1</font> | <font style="background-color:rgba(255, 255, 255, 0);">192.168.10.154</font> | <font style="background-color:rgba(255, 255, 255, 0);">2C2G</font> | <font style="background-color:rgba(255, 255, 255, 0);">work</font> || <font style="background-color:rgba(255, 255, 255, 0);">work2</font> | <font style="background-color:rgba(255, 255, 255, 0);">192.168.10.155</font> | <font style="background-color:rgba(255, 255, 255, 0);">2C2G</font> | <font style="background-color:rgba(255, 255, 255, 0);">work</font> || <font style="background-color:rgba(255, 255, 255, 0);">work3</font> | <font style="background-color:rgba(255, 255, 255, 0);">192.168.10.156</font> | <font style="background-color:rgba(255, 255, 255, 0);">2C2G</font> | <font style="background-color:rgba(255, 255, 255, 0);">work</font> || <font style="background-color:rgba(255, 255, 255, 0);">VIP</font> | <font style="background-color:rgba(255, 255, 255, 0);">192.168.10.150</font> | <font style="background-color:rgba(255, 255, 255, 0);">/</font> | <font style="background-color:rgba(255, 255, 255, 0);">虚拟IP在控制节点上浮动</font> || <font style="background-color:rgba(255, 255, 255, 0);">tiaoban</font> | <font style="background-color:rgba(255, 255, 255, 0);">192.168.10.100</font> | <font style="background-color:rgba(255, 255, 255, 0);">2C2G</font> | <font style="background-color:rgba(255, 255, 255, 0);">客户端，连接管理K8S集群</font> |<h1 id="60fb03bc"><font style="background-color:rgba(255, 255, 255, 0);">基础环境与软件准备</font></h1>---<blockquote><p><font style="background-color:rgba(255, 255, 255, 0);">以下操作在所有节点都执行</font></p></blockquote><h2 id="d77c61bf"><font style="background-color:rgba(255, 255, 255, 0);">修改主机名与hosts文件</font></h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">hostnamectl set-hostname master1</span><br><span class="line">cat &gt; /etc/hosts &lt;&lt; EOF </span><br><span class="line">192.168.10.151   master1</span><br><span class="line">192.168.10.152   master2</span><br><span class="line">192.168.10.153   master3</span><br><span class="line">192.168.10.154   work1</span><br><span class="line">192.168.10.155   work2</span><br><span class="line">192.168.10.156   work3</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h2 id="a0b09c93"><font style="background-color:rgba(255, 255, 255, 0);">验证mac地址uuid</font></h2>---<p><font style="background-color:rgba(255, 255, 255, 0);">保证各节点mac和uuid唯一，防止克隆主机出现网络异常问题</font></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cat /sys/class/net/ens33/address</span><br><span class="line">cat /sys/class/dmi/id/product_uuid </span><br></pre></td></tr></table></figure><h2 id="16c50660"><font style="background-color:rgba(255, 255, 255, 0);">配置时间同步</font></h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">dnf -y install chrony</span><br><span class="line">systemctl  start chronyd</span><br><span class="line">systemctl  enable chronyd</span><br><span class="line">timedatectl set-timezone Asia/Shanghai</span><br><span class="line">chronyc sourcestats -v </span><br><span class="line">date</span><br></pre></td></tr></table></figure><blockquote><p><font style="background-color:rgba(255, 255, 255, 0);">也可以在内网环境其中一台主机启动</font><font style="background-color:rgba(255, 255, 255, 0);">chronyd服务，其他主机配置chronyd服务地址，参考文档：</font><a href="https://www.cuiliangblog.cn/detail/section/31516177"><font style="background-color:rgba(255, 255, 255, 0);">https://www.cuiliangblog.cn/detail/section/31516177</font></a></p></blockquote><h2 id="1663c88c"><font style="background-color:rgba(255, 255, 255, 0);">关闭防火墙和selinux</font></h2>---<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop firewalld.service</span><br><span class="line">systemctl  disable firewalld</span><br><span class="line">setenforce  0</span><br><span class="line">sed  -i &#x27;s/enforcing/disabled/g&#x27; /etc/selinux/config</span><br><span class="line">grep  SELINUX= /etc/selinux/config </span><br></pre></td></tr></table></figure><h2 id="7c54c7f3"><font style="background-color:rgba(255, 255, 255, 0);">关闭swap分区</font></h2>---<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">swapoff -a </span><br><span class="line">sed -i &#x27;/ swap / s/^(.*)$/#\1/g&#x27; /etc/fstab  </span><br></pre></td></tr></table></figure><h2 id="825e7bd1"><font style="background-color:rgba(255, 255, 255, 0);">修改内核相关参数</font></h2>---<p><font style="background-color:rgba(255, 255, 255, 0);">最大限度使用物理内存，</font><font style="background-color:rgba(255, 255, 255, 0);">bridge 设备在二层转发时也去调用 iptables 配置的三层规则，开启数据包转发。</font></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /etc/sysctl.d/kubernetes.conf &lt;&lt; EOF</span><br><span class="line">vm.swappiness = 0</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">net.ipv4.ip_forward = 1</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">sysctl -p /etc/sysctl.d/kubernetes.conf</span><br></pre></td></tr></table></figure><h2 id="927d0791"><font style="background-color:rgba(255, 255, 255, 0);">配置yum源</font></h2>---<p><font style="background-color:rgba(255, 255, 255, 0);">配置阿里源</font></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /etc/yum.repos.d/kubernetes.repo &lt;&lt; EOF </span><br><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=1</span><br><span class="line">repo_gpgcheck=1</span><br><span class="line">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p><font style="background-color:rgba(255, 255, 255, 0);">如果阿里源异常，可切换配置清华源</font></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /etc/yum.repos.d/kubernetes.repo &lt;&lt; EOF </span><br><span class="line">[kubernetes]</span><br><span class="line">name=kubernetes</span><br><span class="line">baseurl=https://mirrors.tuna.tsinghua.edu.cn/kubernetes/yum/repos/kubernetes-el7-$basearch</span><br><span class="line">enabled=1</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h2 id="5e11d2ce"><font style="background-color:rgba(255, 255, 255, 0);">配置ipvs模块功能</font></h2>---<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">dnf -y install ipset ipvsadm </span><br><span class="line"></span><br><span class="line">cat &gt; /etc/sysctl.d/ipvs.modules &lt;&lt;EOF </span><br><span class="line">#!/bin/bash</span><br><span class="line">modprobe -- ip_vs</span><br><span class="line">modprobe -- ip_vs_rr</span><br><span class="line">modprobe -- ip_vs_wrr</span><br><span class="line">modprobe -- ip_vs_sh</span><br><span class="line">modprobe -- nf_conntrack</span><br><span class="line">modprobe -- br_netfilter</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">chmod 755 /etc/sysctl.d/ipvs.modules &amp;&amp; bash </span><br><span class="line"></span><br><span class="line">/etc/sysctl.d/ipvs.modules &amp;&amp; lsmod | grep -e ip_vs -e nf_conntrack </span><br><span class="line">ip_vs_sh               20480  0</span><br><span class="line">ip_vs_wrr              16384  0</span><br><span class="line">ip_vs_rr               16384  0</span><br><span class="line">ip_vs                 180224  6 ip_vs_rr,ip_vs_sh,ip_vs_wrr</span><br><span class="line">nf_conntrack_netlink    53248  0</span><br><span class="line">nf_conntrack          176128  5 xt_conntrack,nf_nat,nf_conntrack_netlink,xt_MASQUERADE,ip_vs</span><br><span class="line">nf_defrag_ipv6         24576  2 nf_conntrack,ip_vs</span><br><span class="line">nf_defrag_ipv4         16384  1 nf_conntrack</span><br><span class="line">nfnetlink              20480  4 nft_compat,nf_conntrack_netlink,nf_tables</span><br><span class="line">libcrc32c              16384  5 nf_conntrack,nf_nat,nf_tables,xfs,ip_vs</span><br><span class="line"></span><br><span class="line"># 添加开机自动加载模块</span><br><span class="line">echo &quot;/etc/sysctl.d/ipvs.modules&quot; &gt;&gt; /etc/rc.local</span><br><span class="line">chmod +x /etc/rc.local</span><br><span class="line"># 启用网桥过滤器模块</span><br><span class="line">echo 1 &gt; /proc/sys/net/bridge/bridge-nf-call-iptables</span><br><span class="line">echo 1 &gt; /proc/sys/net/ipv4/ip_forward</span><br></pre></td></tr></table></figure><h2 id="680cf1ef"><font style="background-color:rgba(255, 255, 255, 0);">安装命令自动补全工具</font></h2>---<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dnf -y install bash-completion </span><br><span class="line">source /etc/profile.d/bash_completion.sh </span><br></pre></td></tr></table></figure><h2 id="752286ce"><font style="background-color:rgba(255, 255, 255, 0);">container</font><font style="background-color:rgba(255, 255, 255, 0);">安装</font></h2>---<h3 id="56f5cf9c"><font style="background-color:rgba(255, 255, 255, 0);">安装软件包</font></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># 安装依赖</span><br><span class="line">dnf install -y yum-utils device-mapper-persistent-data lvm2</span><br><span class="line"></span><br><span class="line"># 添加yum源</span><br><span class="line">dnf config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br><span class="line"></span><br><span class="line"># 查看可安装的containerd版本</span><br><span class="line">dnf list containerd.io.x86_64 --showduplicates | sort -r</span><br><span class="line"></span><br><span class="line"># 安装1.6.22版本containerd</span><br><span class="line">dnf install -y containerd.io-1.6.22-3.1.el8.x86_64</span><br><span class="line"></span><br><span class="line"># 查看版本信息</span><br><span class="line">containerd -v</span><br></pre></td></tr></table></figure><h3 id="da6011d1"><font style="background-color:rgba(255, 255, 255, 0);">配置container</font></h3>**<font style="background-color:rgba(255, 255, 255, 0);">生成默认配置文件</font>**<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">containerd config default &gt; /etc/containerd/config.toml</span><br></pre></td></tr></table></figure><p><strong><font style="background-color:rgba(255, 255, 255, 0);">替换镜像源</font></strong></p><p><font style="background-color:rgba(255, 255, 255, 0);">由于国内环境原因我们需要将 sandbox_image 镜像源设置为阿里云google_containers镜像源。把sandbox_image &#x3D; “k8s.gcr.io&#x2F;pause:3.6”修改为：sandbox_image&#x3D;“registry.aliyuncs.com&#x2F;google_containers&#x2F;pause:3.6”</font></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed -i &#x27;s/sandbox_image\ =.*/sandbox_image\ =\ &quot;registry.aliyuncs.com\/google_containers\/pause:3.6&quot;/g&#x27; /etc/containerd/config.toml|grep sandbox_image</span><br></pre></td></tr></table></figure><p><strong><font style="background-color:rgba(255, 255, 255, 0);">配置cgroup驱动器</font></strong></p><p><font style="background-color:rgba(255, 255, 255, 0);">在 Linux 上，控制组（CGroup）用于限制分配给进程的资源。<br></font><font style="background-color:rgba(255, 255, 255, 0);">kubelet 和底层容器运行时都需要对接控制组 为 Pod 和容器管理资源 ，如 CPU、内存这类资源设置请求和限制。 若要对接控制组（CGroup），kubelet 和容器运行时需要使用一个 cgroup 驱动。 关键的一点是 kubelet 和容器运行时需使用相同的 cgroup 驱动并且采用相同的配置。</font></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed -i &#x27;s/SystemdCgroup\ =\ false/SystemdCgroup\ =\ true/g&#x27; /etc/containerd/config.toml</span><br></pre></td></tr></table></figure><p><strong><font style="background-color:rgba(255, 255, 255, 0);">配置国内镜像加速地址</font></strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># 修改container配置，指定registry配置从文件读取</span><br><span class="line">vim /etc/containerd/config.toml</span><br><span class="line">    [plugins.&quot;io.containerd.grpc.v1.cri&quot;.registry]</span><br><span class="line">      config_path = &quot;/etc/containerd/certs.d&quot;</span><br><span class="line"></span><br><span class="line"># 创建配置文件目录</span><br><span class="line">mkdir -p /etc/containerd/certs.d/docker.io</span><br><span class="line"></span><br><span class="line"># 新增加速配置</span><br><span class="line">cat &gt; /etc/containerd/certs.d/docker.io/hosts.toml &lt;&lt; EOF</span><br><span class="line">server = &quot;https://docker.io&quot;</span><br><span class="line">[host.&quot;https://o2j0mc5x.mirror.aliyuncs.com&quot;]</span><br><span class="line">  capabilities = [&quot;pull&quot;, &quot;resolve&quot;]</span><br><span class="line">server = &quot;https://k8s.gcr.io&quot;</span><br><span class="line">[host.&quot;https://gcr.mirrors.ustc.edu.cn/google-containers/&quot;]</span><br><span class="line">  capabilities = [&quot;pull&quot;, &quot;resolve&quot;]</span><br><span class="line">server = &quot;https://quay.io&quot;</span><br><span class="line">[host.&quot;https://mirror.ccs.tencentyun.com&quot;]</span><br><span class="line">  capabilities = [&quot;pull&quot;, &quot;resolve&quot;]</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="E4Q5q"><font style="background-color:rgba(255, 255, 255, 0);">启动 container服务</font></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl enable containerd --now</span><br></pre></td></tr></table></figure><h3 id="527bcc5b"><font style="background-color:rgba(255, 255, 255, 0);">安装配置crictl</font></h3><font style="background-color:rgba(255, 255, 255, 0);">crictl 是 CRI 兼容的容器运行时命令行接口，和containerd无关，由Kubernetes提供，可以使用它来检查和调试 k8s 节点上的容器运行时和应用程序。</font><p><font style="background-color:rgba(255, 255, 255, 0);">下载地址：<a href="https://github.com/kubernetes-sigs/cri-tools/releases">https://github.com/kubernetes-sigs/cri-tools/releases</a></font></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># 下载</span><br><span class="line">wget https://github.com/kubernetes-sigs/cri-tools/releases/download/v1.27.1/crictl-v1.27.1-linux-amd64.tar.gz</span><br><span class="line"># 解压</span><br><span class="line">tar -zxvf crictl-v1.27.1-linux-amd64.tar.gz -C /usr/local/bin</span><br><span class="line"># 配置</span><br><span class="line">cat &gt; /etc/crictl.yaml &lt;&lt; EOF</span><br><span class="line">runtime-endpoint: &quot;unix:///run/containerd/containerd.sock&quot;</span><br><span class="line">image-endpoint: &quot;unix:///run/containerd/containerd.sock&quot;</span><br><span class="line">timeout: 0</span><br><span class="line">debug: false</span><br><span class="line">pull-image-on-create: false</span><br><span class="line">disable-pull-on-run: false</span><br><span class="line">EOF</span><br><span class="line"># 验证</span><br><span class="line">crictl version</span><br></pre></td></tr></table></figure><h3 id="UomHm"><font style="background-color:rgba(255, 255, 255, 0);">安装配置</font><font style="background-color:rgba(255, 255, 255, 0);">nerdctl(建议)</font></h3><font style="background-color:rgba(255, 255, 255, 0);">containerd虽然可直接提供给终端用户直接使用，也提供了命令行工具(ctr)，但并不是很友好，所以nerdctl应运而生，它也是containerd的命令行工具，支持docker cli关于容器生命周期管理的所有命令，并且支持docker compose (nerdctl compose up)</font><p><font style="background-color:rgba(255, 255, 255, 0);">下载地址：</font><a href="https://github.com/containerd/nerdctl/releases"><font style="background-color:rgba(255, 255, 255, 0);">https://github.com/containerd/nerdctl/releases</font></a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 下载</span><br><span class="line">wget https://github.com/containerd/nerdctl/releases/download/v1.5.0/nerdctl-1.5.0-linux-amd64.tar.gz</span><br><span class="line"># 解压</span><br><span class="line">tar -zxvf nerdctl-1.5.0-linux-amd64.tar.gz </span><br><span class="line"># 复制文件</span><br><span class="line">cp nerdctl /usr/bin/</span><br><span class="line"># 配置 nerdctl 参数自动补齐</span><br><span class="line">echo &#x27;source &lt;(nerdctl completion bash)&#x27; &gt;&gt; /etc/profile</span><br><span class="line">source /etc/profile</span><br><span class="line"># 验证</span><br><span class="line">nerdctl -v</span><br></pre></td></tr></table></figure><h2 id="8dd46c64"><font style="background-color:rgba(255, 255, 255, 0);">安装k8s软件包并配置</font></h2>---<ul><li><font style="background-color:rgba(255, 255, 255, 0);">安装软件包</font></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">yum install -y kubelet kubeadm kubectl </span><br><span class="line"># 默认安装最新版本，如果需要安装老版本，使用如下命令</span><br><span class="line">yum list kubeadm --showduplicates | sort -r</span><br><span class="line">yum install -y kubelet-1.27.6 kubeadm-1.27.6 kubectl-1.27.6</span><br></pre></td></tr></table></figure><ul><li><font style="background-color:rgba(255, 255, 255, 0);">指定kubelet的容器运行时并启动。</font></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">crictl config runtime-endpoint unix:///run/containerd/containerd.sock</span><br><span class="line">systemctl enable kubelet --now</span><br></pre></td></tr></table></figure><ul><li><font style="background-color:rgba(255, 255, 255, 0);">kubectl命令补全</font></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;source &lt;(kubectl completion bash)&quot; &gt;&gt; ~/.bash_profile </span><br><span class="line">source ~/.bash_profile </span><br></pre></td></tr></table></figure><h1 id="6f342ec9"><font style="background-color:rgba(255, 255, 255, 0);">VIP配置(kube-vip)</font></h1>---<blockquote><p><font style="background-color:rgba(255, 255, 255, 0);">以下操作在master1节点执行</font></p></blockquote><h2 id="88210852"><font style="background-color:rgba(255, 255, 255, 0);">准备工作</font></h2><font style="background-color:rgba(255, 255, 255, 0);">我们使用的vip是192.168.10.150</font><p><font style="background-color:rgba(255, 255, 255, 0);">网卡名称是ens160</font></p><p><font style="background-color:rgba(255, 255, 255, 0);">kube-vip使用arp模式</font></p><p><font style="background-color:rgba(255, 255, 255, 0);">参考文档：</font><a href="https://kube-vip.io/docs/installation/static/#kube-vip-as-ha-load-balancer-or-both"><font style="background-color:rgba(255, 255, 255, 0);">https://kube-vip.io/docs/installation/static/#kube-vip-as-ha-load-balancer-or-both</font></a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@master1 ~]# mkdir -p /etc/kubernetes/manifests</span><br><span class="line">[root@master1 ~]# export VIP=192.168.10.150</span><br><span class="line">[root@master1 ~]# export INTERFACE=ens160</span><br><span class="line">[root@master1 ~]# export KVVERSION=v0.8.2</span><br></pre></td></tr></table></figure><h2 id="ea49435f"><font style="background-color:rgba(255, 255, 255, 0);">生成配置文件</font></h2>---<p><font style="background-color:rgba(255, 255, 255, 0);">获取 kube-vip 的 docker 镜像，并在 &#x2F;etc&#x2F;kuberentes&#x2F;manifests 中设置静态 pod 的 yaml 资源清单文件，这样 Kubernetes 就会自动在每个控制平面节点上部署 kube-vip 的 pod 了。</font></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line">[root@master1 ~]# alias kube-vip=&quot;ctr image pull ghcr.io/kube-vip/kube-vip:$KVVERSION; ctr run --rm --net-host ghcr.io/kube-vip/kube-vip:$KVVERSION vip /kube-vip&quot;</span><br><span class="line">[root@master1 ~]# kube-vip manifest pod \</span><br><span class="line">    --interface $INTERFACE \</span><br><span class="line">    --address $VIP \</span><br><span class="line">    --controlplane \</span><br><span class="line">    --services \</span><br><span class="line">    --arp \</span><br><span class="line">    --leaderElection | tee /etc/kubernetes/manifests/kube-vip.yaml</span><br><span class="line"># 生成文件如下所示：</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  creationTimestamp: null</span><br><span class="line">  name: kube-vip</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - args:</span><br><span class="line">    - manager</span><br><span class="line">    env:</span><br><span class="line">    - name: vip_arp</span><br><span class="line">      value: &quot;true&quot;</span><br><span class="line">    - name: port</span><br><span class="line">      value: &quot;6443&quot;</span><br><span class="line">    - name: vip_nodename</span><br><span class="line">      valueFrom:</span><br><span class="line">        fieldRef:</span><br><span class="line">          fieldPath: spec.nodeName</span><br><span class="line">    - name: vip_interface</span><br><span class="line">      value: ens160</span><br><span class="line">    - name: vip_cidr</span><br><span class="line">      value: &quot;32&quot;</span><br><span class="line">    - name: dns_mode</span><br><span class="line">      value: first</span><br><span class="line">    - name: cp_enable</span><br><span class="line">      value: &quot;true&quot;</span><br><span class="line">    - name: cp_namespace</span><br><span class="line">      value: kube-system</span><br><span class="line">    - name: svc_enable</span><br><span class="line">      value: &quot;true&quot;</span><br><span class="line">    - name: svc_leasename</span><br><span class="line">      value: plndr-svcs-lock</span><br><span class="line">    - name: vip_leaderelection</span><br><span class="line">      value: &quot;true&quot;</span><br><span class="line">    - name: vip_leasename</span><br><span class="line">      value: plndr-cp-lock</span><br><span class="line">    - name: vip_leaseduration</span><br><span class="line">      value: &quot;5&quot;</span><br><span class="line">    - name: vip_renewdeadline</span><br><span class="line">      value: &quot;3&quot;</span><br><span class="line">    - name: vip_retryperiod</span><br><span class="line">      value: &quot;1&quot;</span><br><span class="line">    - name: address</span><br><span class="line">      value: 192.168.10.150</span><br><span class="line">    - name: prometheus_server</span><br><span class="line">      value: :2112</span><br><span class="line">    image: ghcr.io/kube-vip/kube-vip:v0.8.2</span><br><span class="line">    imagePullPolicy: IfNotPresent</span><br><span class="line">    name: kube-vip</span><br><span class="line">    resources: &#123;&#125;</span><br><span class="line">    securityContext:</span><br><span class="line">      capabilities:</span><br><span class="line">        add:</span><br><span class="line">        - NET_ADMIN</span><br><span class="line">        - NET_RAW</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - mountPath: /etc/kubernetes/admin.conf</span><br><span class="line">      name: kubeconfig</span><br><span class="line">  hostAliases:</span><br><span class="line">  - hostnames:</span><br><span class="line">    - kubernetes</span><br><span class="line">    ip: 127.0.0.1</span><br><span class="line">  hostNetwork: true</span><br><span class="line">  volumes:</span><br><span class="line">  - hostPath:</span><br><span class="line">      path: /etc/kubernetes/admin.conf</span><br><span class="line">    name: kubeconfig</span><br><span class="line">status: &#123;&#125;</span><br></pre></td></tr></table></figure><p><font style="background-color:rgba(255, 255, 255, 0);">当执行完kubeadm init后，kubelet会去加载这里面的yaml创建kube-vip容器。</font></p><h2 id="cce0e451"><font style="background-color:rgba(255, 255, 255, 0);">拷贝至其他master节点</font></h2>---<p><font style="background-color:rgba(255, 255, 255, 0);">所有master节点都需要部署一个kube-vip，我们只需要将yaml文件存放在&#x2F;etc&#x2F;kubernetes&#x2F;manifests&#x2F;目录下，kubelet启动时会自动加载资源清单并创建pod。</font></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@master1 ~]# scp /etc/kubernetes/manifests/kube-vip.yaml master2:/etc/kubernetes/manifests/kube-vip.yaml</span><br><span class="line">[root@master1 ~]# scp /etc/kubernetes/manifests/kube-vip.yaml master3:/etc/kubernetes/manifests/kube-vip.yaml</span><br></pre></td></tr></table></figure><p><font style="background-color:rgba(255, 255, 255, 0);">master1节点修改挂载配置文件(在1.29以上时使用super-admin.conf文件)，具体可参考文档</font><a href="https://github.com/kube-vip/kube-vip/issues/684"><font style="background-color:rgba(255, 255, 255, 0);">kube-vip 需要使用 Kubernetes 1.29 的 super-admin.conf ·期刊 #684 ·kube-vip&#x2F;kube-vip (github.com)</font></a><font style="background-color:rgba(255, 255, 255, 0);">。其他master节点无需修改。</font></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sed -i &#x27;s#path: /etc/kubernetes/admin.conf#path: /etc/kubernetes/super-admin.conf#&#x27; \</span><br><span class="line">          /etc/kubernetes/manifests/kube-vip.yaml</span><br></pre></td></tr></table></figure><h1 id="9845b730"><font style="background-color:rgba(255, 255, 255, 0);">VIP配置(keepalived+haproxy)</font></h1>---<p><font style="background-color:rgba(255, 255, 255, 0);">以下操作在所有master节点执行</font></p><h2 id="bbd75de9"><font style="background-color:rgba(255, 255, 255, 0);">haproxy配置</font></h2>---<p><font style="background-color:rgba(255, 255, 255, 0);">安装haproxy</font></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master1 ~]# dnf -y install haproxy</span><br></pre></td></tr></table></figure><p><font style="background-color:rgba(255, 255, 255, 0);">编辑配置文件，所有master节点配置一样。</font></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">[root@master1 ~]# vim /etc/haproxy/haproxy.cfg</span><br><span class="line">global</span><br><span class="line">    log         127.0.0.1 local2</span><br><span class="line">    pidfile     /var/run/haproxy.pid</span><br><span class="line">    maxconn     4000</span><br><span class="line">defaults</span><br><span class="line">    mode                    http</span><br><span class="line">    log                     global</span><br><span class="line">    option                  dontlognull</span><br><span class="line">    option http-server-close</span><br><span class="line">    option                  redispatch</span><br><span class="line">    retries                 3</span><br><span class="line">    timeout http-request    10s</span><br><span class="line">    timeout queue           1m</span><br><span class="line">    timeout connect         10s</span><br><span class="line">    timeout client          1m</span><br><span class="line">    timeout server          1m</span><br><span class="line">    timeout http-keep-alive 10s</span><br><span class="line">    timeout check           10s</span><br><span class="line">    maxconn                 3000</span><br><span class="line"></span><br><span class="line">listen admin_stats</span><br><span class="line">    bind    *:8888    #监听的ip端口号</span><br><span class="line">    stats   enable</span><br><span class="line">    stats   refresh 30s   #统计页面自动刷新时间</span><br><span class="line">    stats   uri /admin    #访问的uri   ip:8080/admin</span><br><span class="line">    stats   realm haproxy</span><br><span class="line">    stats   auth admin:Miaohua123!  #认证用户名和密码</span><br><span class="line">    stats   hide-version   #隐藏HAProxy的版本号</span><br><span class="line">    stats   admin if TRUE   #管理界面，如果认证成功了，可通过webui管理节点  </span><br><span class="line"></span><br><span class="line">frontend  kubernetes-apiserver</span><br><span class="line">    mode tcp</span><br><span class="line">    bind *:9443</span><br><span class="line">    # bind *:443 ssl # To be completed ....</span><br><span class="line">    default_backend             kubernetes-apiserver</span><br><span class="line"></span><br><span class="line">backend kubernetes-apiserver</span><br><span class="line">    mode        tcp</span><br><span class="line">    balance     roundrobin</span><br><span class="line"># k8s-apiservers backend</span><br><span class="line">    server master1 192.168.10.151:6443 check</span><br><span class="line">    server master2 192.168.10.152:6443 check</span><br><span class="line">    server master3 192.168.10.153:6443 check</span><br></pre></td></tr></table></figure><p><font style="background-color:rgba(255, 255, 255, 0);">启动服务并验证</font></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@master1 ~]# systemctl start haproxy.service </span><br><span class="line">[root@master1 ~]# systemctl enable haproxy.service </span><br><span class="line">[root@master1 ~]# ss -tnlp | grep haproxy</span><br><span class="line">LISTEN    0         3000               0.0.0.0:8888             0.0.0.0:*        users:((&quot;haproxy&quot;,pid=7062,fd=6))                                              </span><br><span class="line">LISTEN    0         3000               0.0.0.0:9443             0.0.0.0:*        users:((&quot;haproxy&quot;,pid=7062,fd=8)) </span><br></pre></td></tr></table></figure><h2 id="fff6cb90"><font style="background-color:rgba(255, 255, 255, 0);">keepalived配置</font></h2>---<p><font style="background-color:rgba(255, 255, 255, 0);">安装keepalived服务</font></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master1 ~]# dnf -y install keepalived</span><br></pre></td></tr></table></figure><p><font style="background-color:rgba(255, 255, 255, 0);">添加keepalived配置文件，master1节点内容如下。master2节点state改为BACKUP，priority改为99。master3节点state改为BACKUP，priority改为98。</font></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">[root@master1 ~]# vim /etc/keepalived/keepalived.conf</span><br><span class="line">global_defs &#123;</span><br><span class="line">   script_user root</span><br><span class="line">   enable_script_security</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_script chk_haproxy &#123;</span><br><span class="line">    script &quot;/etc/keepalived/check.sh&quot;</span><br><span class="line">    interval 1</span><br><span class="line">    weight -2</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">  state MASTER # 实例类型</span><br><span class="line">  interface ens33 # 网卡名称</span><br><span class="line">  virtual_router_id 201</span><br><span class="line">  priority 100 # 优先级</span><br><span class="line">  advert_int 1</span><br><span class="line"></span><br><span class="line">  virtual_ipaddress &#123;</span><br><span class="line">    192.168.10.150/32</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  authentication &#123;</span><br><span class="line">    auth_type PASS</span><br><span class="line">    auth_pass 1111</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  track_script &#123;</span><br><span class="line">      chk_haproxy</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><font style="background-color:rgba(255, 255, 255, 0);">添加服务检测脚本，如果containerd进程停止则进行故障切换</font></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@master1 ~]# vim /etc/keepalived/check.sh</span><br><span class="line">#!/bin/bash</span><br><span class="line">if systemctl is-active --quiet containerd; then</span><br><span class="line">    exit 0</span><br><span class="line">else</span><br><span class="line">    exit 1</span><br><span class="line">fi</span><br><span class="line">[root@master1 ~]# chmod +x /etc/keepalived/check.sh</span><br></pre></td></tr></table></figure><p><font style="background-color:rgba(255, 255, 255, 0);">启动服务并验证</font></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@master1 ~]# systemctl start keepalived.service </span><br><span class="line">[root@master1 ~]# systemctl enable keepalived</span><br><span class="line">[root@master1 ~]# ip a | grep 192.168.10</span><br><span class="line">    inet 192.168.10.151/24 brd 192.168.10.255 scope global ens33</span><br><span class="line">    inet 192.168.10.150/32 scope global ens33</span><br></pre></td></tr></table></figure><h1 id="ede357c3"><font style="background-color:rgba(255, 255, 255, 0);">初始化master节点</font></h1>---<blockquote><p><font style="background-color:rgba(255, 255, 255, 0);">以下操作在master1节点执行</font></p></blockquote><h2 id="575087eb"><font style="background-color:rgba(255, 255, 255, 0);">配置集群参数</font></h2>---<p><font style="background-color:rgba(255, 255, 255, 0);">获取默认的初始化参数文件</font></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master1 ~]# kubeadm config print init-defaults &gt; kubeadm-conf.yaml</span><br></pre></td></tr></table></figure><p><font style="background-color:rgba(255, 255, 255, 0);">修改配置文件</font></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line">[root@master1 ~]# cat kubeadm-conf.yaml</span><br><span class="line">apiVersion: kubeadm.k8s.io/v1beta3</span><br><span class="line">bootstrapTokens:</span><br><span class="line">- groups:</span><br><span class="line">  - system:bootstrappers:kubeadm:default-node-token</span><br><span class="line">  token: abcdef.0123456789abcdef</span><br><span class="line">  ttl: 24h0m0s</span><br><span class="line">  usages:</span><br><span class="line">  - signing</span><br><span class="line">  - authentication</span><br><span class="line">kind: InitConfiguration</span><br><span class="line">localAPIEndpoint:</span><br><span class="line">  advertiseAddress: 192.168.10.151  # 指定当前master1节点IP</span><br><span class="line">  bindPort: 6443 # 当前master1节点端口</span><br><span class="line">nodeRegistration:</span><br><span class="line">  criSocket: unix:///run/containerd/containerd.sock # 使用containerd的socket地址</span><br><span class="line">  imagePullPolicy: IfNotPresent</span><br><span class="line">  name: master1 # 节点主机名</span><br><span class="line">  taints: null</span><br><span class="line">---</span><br><span class="line">apiServer:</span><br><span class="line">  extraArgs:</span><br><span class="line">    authorization-mode: Node,RBAC</span><br><span class="line">  timeoutForControlPlane: 4m0s</span><br><span class="line">  certSANs:  # 添加其他master节点的相关信息</span><br><span class="line">  - 127.0.0.1</span><br><span class="line">  - master1</span><br><span class="line">  - master2</span><br><span class="line">  - master3</span><br><span class="line">  - 192.168.10.150</span><br><span class="line">  - 192.168.10.151</span><br><span class="line">  - 192.168.10.152</span><br><span class="line">  - 192.168.10.153</span><br><span class="line">apiVersion: kubeadm.k8s.io/v1beta3</span><br><span class="line">certificatesDir: /etc/kubernetes/pki</span><br><span class="line">clusterName: kubernetes</span><br><span class="line">controllerManager: &#123;&#125;</span><br><span class="line">dns: &#123;&#125;</span><br><span class="line">etcd:</span><br><span class="line">  local:</span><br><span class="line">    dataDir: /var/lib/etcd</span><br><span class="line">imageRepository: registry.aliyuncs.com/google_containers # 阿里云镜像</span><br><span class="line">kind: ClusterConfiguration</span><br><span class="line">kubernetesVersion: 1.27.6 # k8s版本</span><br><span class="line">controlPlaneEndpoint: 192.168.10.150:6443  # 设置控制平面Endpoint地址和端口</span><br><span class="line">networking:</span><br><span class="line">  dnsDomain: cluster.local</span><br><span class="line">  serviceSubnet: 10.96.0.0/12</span><br><span class="line">  podSubnet: 10.244.0.0/16  # 指定 pod 子网</span><br><span class="line">scheduler: &#123;&#125;</span><br><span class="line">---</span><br><span class="line"># 指定kube-proxy基于ipvs模式</span><br><span class="line">apiVersion: kubeproxy.config.k8s.io/v1alpha1</span><br><span class="line">kind:  KubeProxyConfiguration</span><br><span class="line">mode: ipvs</span><br><span class="line">---</span><br><span class="line">apiVersion: kubelet.config.k8s.io/v1beta1</span><br><span class="line">authentication:</span><br><span class="line">  anonymous:</span><br><span class="line">    enabled: false</span><br><span class="line">  webhook:</span><br><span class="line">    cacheTTL: 0s</span><br><span class="line">    enabled: true</span><br><span class="line">  x509:</span><br><span class="line">    clientCAFile: /etc/kubernetes/pki/ca.crt</span><br><span class="line">authorization:</span><br><span class="line">  mode: Webhook</span><br><span class="line">  webhook:</span><br><span class="line">    cacheAuthorizedTTL: 0s</span><br><span class="line">    cacheUnauthorizedTTL: 0s</span><br><span class="line">cgroupDriver: systemd   # 指定cgroup驱动器为systemd模式</span><br><span class="line">clusterDNS:</span><br><span class="line">- 10.96.0.10</span><br><span class="line">clusterDomain: cluster.local</span><br><span class="line">cpuManagerReconcilePeriod: 0s</span><br><span class="line">evictionPressureTransitionPeriod: 0s</span><br><span class="line">fileCheckFrequency: 0s</span><br><span class="line">healthzBindAddress: 127.0.0.1</span><br><span class="line">healthzPort: 10248</span><br><span class="line">httpCheckFrequency: 0s</span><br><span class="line">imageMinimumGCAge: 0s</span><br><span class="line">kind: KubeletConfiguration</span><br><span class="line">logging: &#123;&#125;</span><br><span class="line">memorySwap: &#123;&#125;</span><br><span class="line">nodeStatusReportFrequency: 0s</span><br><span class="line">nodeStatusUpdateFrequency: 0s</span><br><span class="line">rotateCertificates: true</span><br><span class="line">runtimeRequestTimeout: 0s</span><br><span class="line">shutdownGracePeriod: 0s</span><br><span class="line">shutdownGracePeriodCriticalPods: 0s</span><br><span class="line">staticPodPath: /etc/kubernetes/manifests</span><br><span class="line">streamingConnectionIdleTimeout: 0s</span><br><span class="line">syncFrequency: 0s</span><br><span class="line">volumeStatsAggPeriod: 0s</span><br></pre></td></tr></table></figure><p><font style="background-color:rgba(255, 255, 255, 0);">对于上面的资源清单的文档比较杂，要想完整了解上面的资源对象对应的属性，可以查看对应的 godoc 文档，地址:</font><font style="background-color:rgba(255, 255, 255, 0);"> </font><a href="https://godoc.org/k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/v1beta3"><font style="background-color:rgba(255, 255, 255, 0);">https://godoc.org/k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/v1beta3</font></a></p><h2 id="aec284f8"><font style="background-color:rgba(255, 255, 255, 0);">拉取镜像</font></h2>---<p><font style="background-color:rgba(255, 255, 255, 0);">将master1节点的kubeadm-conf.yaml复制到其他master节点，所有master节点都提前执行</font></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@master1 ~]# kubeadm config images pull --config kubeadm-conf.yaml</span><br><span class="line">[config/images] Pulled registry.aliyuncs.com/google_containers/kube-apiserver:v1.27.6</span><br><span class="line">[config/images] Pulled registry.aliyuncs.com/google_containers/kube-controller-manager:v1.27.6</span><br><span class="line">[config/images] Pulled registry.aliyuncs.com/google_containers/kube-scheduler:v1.27.6</span><br><span class="line">[config/images] Pulled registry.aliyuncs.com/google_containers/kube-proxy:v1.27.6</span><br><span class="line">[config/images] Pulled registry.aliyuncs.com/google_containers/pause:3.9</span><br><span class="line">[config/images] Pulled registry.aliyuncs.com/google_containers/etcd:3.5.7-0</span><br><span class="line">[config/images] Pulled registry.aliyuncs.com/google_containers/coredns:v1.10.1</span><br><span class="line"># CRI sandbox(pause) image默认使用registry.k8s.io/pause:3.6，由于网络原因无法拉取，直接改为阿里镜像标签即可。</span><br><span class="line">[root@master1 ~]# nerdctl -n k8s.io tag registry.aliyuncs.com/google_containers/pause:3.9 registry.k8s.io/pause:3.6</span><br></pre></td></tr></table></figure><h2 id="5fa25176"><font style="background-color:rgba(255, 255, 255, 0);">集群初始化</font></h2>---<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">[root@master1 ~]# kubeadm init --upload-certs --config=kubeadm-conf.yaml </span><br><span class="line">Your Kubernetes control-plane has initialized successfully!</span><br><span class="line"></span><br><span class="line">To start using your cluster, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">  mkdir -p $HOME/.kube</span><br><span class="line">  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">  sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line"></span><br><span class="line">Alternatively, if you are the root user, you can run:</span><br><span class="line"></span><br><span class="line">  export KUBECONFIG=/etc/kubernetes/admin.conf</span><br><span class="line"></span><br><span class="line">You should now deploy a pod network to the cluster.</span><br><span class="line">Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:</span><br><span class="line">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class="line"></span><br><span class="line">You can now join any number of the control-plane node running the following command on each as root:</span><br><span class="line"></span><br><span class="line">  kubeadm join 192.168.10.150:6443 --token abcdef.0123456789abcdef \</span><br><span class="line">        --discovery-token-ca-cert-hash sha256:4f8a53db87e99a4f3e8512169b7269ef2e28779e4602c0c3df898c645973c88c \</span><br><span class="line">        --control-plane --certificate-key efde545c8ea984be7ce9449ea1e77eb44659f1708001be512b7e01f70cf568b7</span><br><span class="line"></span><br><span class="line">Please note that the certificate-key gives access to cluster sensitive data, keep it secret!</span><br><span class="line">As a safeguard, uploaded-certs will be deleted in two hours; If necessary, you can use</span><br><span class="line">&quot;kubeadm init phase upload-certs --upload-certs&quot; to reload certs afterward.</span><br><span class="line"></span><br><span class="line">Then you can join any number of worker nodes by running the following on each as root:</span><br><span class="line"></span><br><span class="line">kubeadm join 192.168.10.150:6443 --token abcdef.0123456789abcdef \</span><br><span class="line">        --discovery-token-ca-cert-hash sha256:4f8a53db87e99a4f3e8512169b7269ef2e28779e4602c0c3df898c645973c88c</span><br></pre></td></tr></table></figure><ul><li><font style="background-color:rgba(255, 255, 255, 0);">–upload-certs 标志用来将在所有控制平面实例之间的共享证书上传到集群。然后根据安装提示拷贝 kubeconfig 文件</font></li><li><font style="background-color:rgba(255, 255, 255, 0);">如果配置问题导致集群初始化失败，可重置集群再次初始化：</font></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@master1 ~]# kubeadm reset</span><br><span class="line">[root@master1 ~]# ipvsadm --clear</span><br><span class="line">[root@master1 ~]# rm -rf $HOME/.kube/config</span><br></pre></td></tr></table></figure><h2 id="c238630b"><font style="background-color:rgba(255, 255, 255, 0);">根据提示配置环境变量</font></h2>---<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@master1 ~]# mkdir -p $HOME/.kube </span><br><span class="line">[root@master1 ~]# cp -i /etc/kubernetes/admin.conf $HOME/.kube/config </span><br><span class="line">[root@master1 ~]# chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line">[root@master1 ~]# echo &quot;export KUBECONFIG=/etc/kubernetes/admin.conf&quot; &gt;&gt; ~/.bash_profile</span><br><span class="line">[root@tiaoban ~]# source ~/.bash_profile</span><br></pre></td></tr></table></figure><h2 id="154df728"><font style="background-color:rgba(255, 255, 255, 0);">安装flannel网络</font></h2>---<ul><li><font style="background-color:rgba(255, 255, 255, 0);">下载资源清单配置文件</font></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master1 ~]# wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</span><br></pre></td></tr></table></figure><ul><li><font style="background-color:rgba(255, 255, 255, 0);">创建资源</font></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master1 ~]# kubectl apply -f kube-flannel.yml</span><br></pre></td></tr></table></figure><ul><li><font style="background-color:rgba(255, 255, 255, 0);">如果镜像不能正常拉取，所有节点需提前导入镜像，并修改yaml文件镜像拉取策略</font></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">imagePullPolicy: IfNotPresent</span><br></pre></td></tr></table></figure><ul><li><font style="background-color:rgba(255, 255, 255, 0);">镜像导入与查询</font></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@work3 ~]# ctr -n=k8s.io image import flannel.tar </span><br><span class="line">unpacking docker.io/flannel/flannel:v0.22.1 (sha256:0b78f714708e837ae667c204cc918649ebcf2441b1d18ebde9a6564254932ee5)...done</span><br><span class="line">[root@work3 ~]# crictl images</span><br><span class="line">IMAGE                                                             TAG                 IMAGE ID            SIZE</span><br><span class="line">docker.io/flannel/flannel-cni-plugin                              v1.2.0              a55d1bad692b7       8.32MB</span><br></pre></td></tr></table></figure><h1 id="76ce2493"><font style="background-color:rgba(255, 255, 255, 0);">其他节点加入集群</font></h1>---<h2 id="6e7aaa3e"><font style="background-color:rgba(255, 255, 255, 0);">master节点加入集群</font></h2>---<p><font style="background-color:rgba(255, 255, 255, 0);">另外两个节点 master2 和 master3 都执行上面的 join 命令，上面的命令中的 –control-plane 就是通知 kubeadm join 创建一个新的控制平面，–certificate-key 会从集群中的 kubeadm-certs Secret 下载控制平面证书并使用给定的密钥进行解密。</font></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 以master2节点为例</span><br><span class="line">[root@master2 ~]#   kubeadm join 192.168.10.150:6443 --token abcdef.0123456789abcdef \</span><br><span class="line">&gt;         --discovery-token-ca-cert-hash sha256:4f8a53db87e99a4f3e8512169b7269ef2e28779e4602c0c3df898c645973c88c \</span><br><span class="line">&gt;         --control-plane --certificate-key efde545c8ea984be7ce9449ea1e77eb44659f1708001be512b7e01f70cf568b7</span><br><span class="line"></span><br><span class="line"># 然后根据提示配置环境变量</span><br><span class="line">[root@master2 ~]# mkdir -p $HOME/.kube</span><br><span class="line">[root@master2 ~]# cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">[root@master2 ~]# chown $(id -u):$(id -g) $HOME/.kube/config</span><br></pre></td></tr></table></figure><h2 id="5eec51f2"><font style="background-color:rgba(255, 255, 255, 0);">work节点加入集群</font></h2>---<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubeadm join 192.168.10.150:6443 --token abcdef.0123456789abcdef \</span><br><span class="line">        --discovery-token-ca-cert-hash sha256:4f8a53db87e99a4f3e8512169b7269ef2e28779e4602c0c3df898c645973c88c</span><br></pre></td></tr></table></figure><h2 id="ade4c21a"><font style="background-color:rgba(255, 255, 255, 0);">client配置</font></h2>---<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 安装指定版本的kubelet</span><br><span class="line">[root@tiaoban ~]# yum install -y kubectl-1.27.6</span><br><span class="line"># 拷贝集群认证文件并配置环境变量</span><br><span class="line">[root@tiaoban ~]# mkdir -p /etc/kubernetes</span><br><span class="line">[root@tiaoban ~]# scp master1:/etc/kubernetes/admin.conf /etc/kubernetes/</span><br><span class="line">[root@tiaoban ~]# echo &quot;export KUBECONFIG=/etc/kubernetes/admin.conf&quot; &gt;&gt; ~/.bash_profile</span><br><span class="line">[root@tiaoban ~]# source ~/.bash_profile</span><br></pre></td></tr></table></figure><h1 id="fb2d3f91"><font style="background-color:rgba(255, 255, 255, 0);">集群验证</font></h1>---<blockquote><p><font style="background-color:rgba(255, 255, 255, 0);">以下操作在tiaoban节点执行</font></p></blockquote><h2 id="77b07675"><font style="background-color:rgba(255, 255, 255, 0);">查看节点信息</font></h2>---<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@tiaoban ~]# kubectl get node</span><br><span class="line">NAME      STATUS   ROLES           AGE    VERSION</span><br><span class="line">master1   Ready    control-plane   18m     v1.27.6</span><br><span class="line">master2   Ready    control-plane   12m7s   v1.27.6</span><br><span class="line">master3   Ready    control-plane   13m6s   v1.27.6</span><br><span class="line">work1     Ready    &lt;none&gt;          8m25s   v1.27.6</span><br><span class="line">work2     Ready    &lt;none&gt;          8m21s   v1.27.6</span><br><span class="line">work3     Ready    &lt;none&gt;          8m17s   v1.27.6</span><br></pre></td></tr></table></figure><h2 id="86a835fd"><font style="background-color:rgba(255, 255, 255, 0);">查看pod信息</font></h2>---<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">[root@master1 ~]# kubectl get pod -A -o wide </span><br><span class="line">NAMESPACE      NAME                              READY   STATUS    RESTARTS       AGE     IP               NODE      NOMINATED NODE   READINESS GATES</span><br><span class="line">kube-flannel   kube-flannel-ds-2nqk5             1/1     Running   0              134s   192.168.10.151   master1   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-flannel   kube-flannel-ds-c87jk             1/1     Running   0              134s   192.168.10.155   work2     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-flannel   kube-flannel-ds-hnps5             1/1     Running   0              134s   192.168.10.154   work1     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-flannel   kube-flannel-ds-jphgx             1/1     Running   0              154s   192.168.10.153   master3   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-flannel   kube-flannel-ds-lxpsp             1/1     Running   0              134s   192.168.10.156   work3     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-flannel   kube-flannel-ds-rx5kf             1/1     Running   0              134s   192.168.10.152   master2   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system    coredns-7bdc4cb885-cjbbx          1/1     Running   0              14m    10.244.5.3       work1     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system    coredns-7bdc4cb885-sgsns          1/1     Running   0              14m    10.244.5.2       work1     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system    etcd-master1                      1/1     Running   1              14m    192.168.10.151   master1   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system    etcd-master2                      1/1     Running   0              15m    192.168.10.152   master2   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system    etcd-master3                      1/1     Running   0              14m    192.168.10.153   master3   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system    kube-apiserver-master1            1/1     Running   1              14m    192.168.10.151   master1   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system    kube-apiserver-master2            1/1     Running   0              15m    192.168.10.152   master2   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system    kube-apiserver-master3            1/1     Running   2 (154m ago)   14m    192.168.10.153   master3   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system    kube-controller-manager-master1   1/1     Running   3 (40m ago)    14m    192.168.10.151   master1   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system    kube-controller-manager-master2   1/1     Running   0              15m    192.168.10.152   master2   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system    kube-controller-manager-master3   1/1     Running   0              14m    192.168.10.153   master3   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system    kube-proxy-9jsq7                  1/1     Running   0              18m    192.168.10.155   work2     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system    kube-proxy-cpb5n                  1/1     Running   0              14m    192.168.10.151   master1   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system    kube-proxy-dm2rm                  1/1     Running   0              14m    192.168.10.153   master3   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system    kube-proxy-g26c4                  1/1     Running   0              15m    192.168.10.152   master2   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system    kube-proxy-jkhnj                  1/1     Running   0              18m    192.168.10.156   work3     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system    kube-proxy-x29d9                  1/1     Running   0              18m    192.168.10.154   work1     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system    kube-scheduler-master1            1/1     Running   3 (39m ago)    14m    192.168.10.151   master1   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system    kube-scheduler-master2            1/1     Running   0              15m    192.168.10.152   master2   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system    kube-scheduler-master3            1/1     Running   0              14m    192.168.10.153   master3   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system    kube-vip-master1                  1/1     Running   0              1m     192.168.10.151   master1   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system    kube-vip-master2                  1/1     Running   1 (38m ago)    15m    192.168.10.152   master2   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system    kube-vip-master3                  1/1     Running   0              14m    192.168.10.153   master3   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure><h1 id="da88e661"><font style="background-color:rgba(255, 255, 255, 0);">集群高可用测试</font></h1>---<h2 id="87c533b1"><font style="background-color:rgba(255, 255, 255, 0);">组件所在节点查看</font></h2>---<p><font style="background-color:rgba(255, 255, 255, 0);">查看VIP所在节点（当前位于master2）</font></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@tiaoban ~]# ansible k8s-ha -m shell -a &quot;ip a | grep 192.168.10.150&quot;</span><br><span class="line">[WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details</span><br><span class="line">work2 | FAILED | rc=1 &gt;&gt;</span><br><span class="line">non-zero return code</span><br><span class="line">master2 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">    inet 192.168.10.150/32 scope global ens160</span><br><span class="line">work1 | FAILED | rc=1 &gt;&gt;</span><br><span class="line">non-zero return code</span><br><span class="line">master1 | FAILED | rc=1 &gt;&gt;</span><br><span class="line">non-zero return code</span><br><span class="line">master3 | FAILED | rc=1 &gt;&gt;</span><br><span class="line">non-zero return code</span><br><span class="line">work3 | FAILED | rc=1 &gt;&gt;</span><br><span class="line">non-zero return code</span><br></pre></td></tr></table></figure><p><font style="background-color:rgba(255, 255, 255, 0);">查看其他组件所在节点（controller-manager位于master1，scheduler 位于master3）</font></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@tiaoban ~]# kubectl get leases -n kube-system</span><br><span class="line">NAME                                   HOLDER                                                                      AGE</span><br><span class="line">apiserver-bqv2ezepcsovu7bfu7lvbrdg2m   apiserver-bqv2ezepcsovu7bfu7lvbrdg2m_c3892ab2-71ee-40f4-be66-4f65c664f568   175m</span><br><span class="line">apiserver-bskcrn2i4gf5c5gco6huepssle   apiserver-bskcrn2i4gf5c5gco6huepssle_00e69eb5-4df9-4c3d-87e0-2eb54d7d93c4   3h6m</span><br><span class="line">apiserver-s5dbgrswajhxxnkoaowmosesjm   apiserver-s5dbgrswajhxxnkoaowmosesjm_3665e3ce-dc72-440d-ba7a-ff08f9c71b6a   176m</span><br><span class="line">kube-controller-manager                master1_08adefe3-56c0-4c87-94b7-9adda172eaf3                                3h6m</span><br><span class="line">kube-scheduler                         master3_59611769-b42d-459a-aa45-6ccf535d793f                                3h6m</span><br><span class="line">plndr-cp-lock                          master3                                                                     176m</span><br><span class="line">plndr-svcs-lock                        master1                                                                     176m</span><br></pre></td></tr></table></figure><p><font style="background-color:rgba(255, 255, 255, 0);">创建deployment和svc，模拟生产业务</font></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"># 新建资源清单</span><br><span class="line">[root@tiaoban k8s]# cat &gt; demo.yaml &lt;&lt; EOF</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: myapp</span><br><span class="line">spec:</span><br><span class="line">  replicas: 3</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: myapp</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: myapp</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: myapp</span><br><span class="line">        image: ikubernetes/myapp:v1</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br><span class="line">          name: http</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: myapp-svc</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    app: myapp</span><br><span class="line">  type: NodePort</span><br><span class="line">  ports:</span><br><span class="line">  - port: 80</span><br><span class="line">    targetPort:  80</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"># 创建资源</span><br><span class="line">[root@tiaoban k8s]# kubectl apply -f demo.yaml </span><br><span class="line">deployment.apps/myapp created</span><br><span class="line">service/myapp-svc created</span><br><span class="line"></span><br><span class="line"># 查看资源信息</span><br><span class="line">[root@tiaoban k8s]# kubectl get pod -o wide</span><br><span class="line">NAME                     READY   STATUS    RESTARTS   AGE    IP           NODE    NOMINATED NODE   READINESS GATES</span><br><span class="line">myapp-64b6b8fbcd-jm5q2   1/1     Running   0          101s   10.244.3.2   work3   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">myapp-64b6b8fbcd-qqjsd   1/1     Running   0          101s   10.244.4.2   work2   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">myapp-64b6b8fbcd-tsmwx   1/1     Running   0          101s   10.244.5.6   work1   &lt;none&gt;           &lt;none&gt;</span><br><span class="line"></span><br><span class="line">[root@tiaoban k8s]# kubectl get svc</span><br><span class="line">NAME         TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE</span><br><span class="line">kubernetes   ClusterIP   10.96.0.1        &lt;none&gt;        443/TCP        3h17m</span><br><span class="line">myapp-svc    NodePort    10.110.186.236   &lt;none&gt;        80:30380/TCP   5m6s</span><br><span class="line"></span><br><span class="line"># 访问测试</span><br><span class="line">[root@tiaoban k8s]# curl 192.168.10.150:30380</span><br><span class="line">Hello MyApp | Version: v1 | &lt;a href=&quot;hostname.html&quot;&gt;Pod Name&lt;/a&gt;</span><br></pre></td></tr></table></figure><h2 id="59ab63b0"><font style="background-color:rgba(255, 255, 255, 0);">宕机一台控制节点</font></h2>---<p><font style="background-color:rgba(255, 255, 255, 0);">将VIP所在的master2节点关机，模拟宕机</font></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master3 ~]# init 0</span><br></pre></td></tr></table></figure><p><font style="background-color:rgba(255, 255, 255, 0);">各组件信息查看</font></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"># VIP位于master1</span><br><span class="line">[root@tiaoban k8s]# ansible k8s-ha -m shell -a &quot;ip a | grep 192.168.10.150&quot;</span><br><span class="line">[WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details</span><br><span class="line">[WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details</span><br><span class="line">master2 | UNREACHABLE! =&gt; &#123;</span><br><span class="line">    &quot;changed&quot;: false,</span><br><span class="line">    &quot;msg&quot;: &quot;Failed to connect to the host via ssh: ssh: connect to host master2 port 22: Connection refused&quot;,</span><br><span class="line">    &quot;unreachable&quot;: true</span><br><span class="line">&#125;</span><br><span class="line">work2 | FAILED | rc=1 &gt;&gt;</span><br><span class="line">non-zero return code</span><br><span class="line">work3 | FAILED | rc=1 &gt;&gt;</span><br><span class="line">non-zero return code</span><br><span class="line">work1 | FAILED | rc=1 &gt;&gt;</span><br><span class="line">non-zero return code</span><br><span class="line">master3 | FAILED | rc=1 &gt;&gt;</span><br><span class="line">non-zero return code</span><br><span class="line">master1 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">    inet 192.168.10.150/32 scope global ens160</span><br><span class="line"></span><br><span class="line"># controller-manager位于master1 scheduler位于master3</span><br><span class="line">[root@tiaoban k8s]# kubectl get leases -n kube-system</span><br><span class="line">NAME                                   HOLDER                                                                      AGE</span><br><span class="line">apiserver-bqv2ezepcsovu7bfu7lvbrdg2m   apiserver-bqv2ezepcsovu7bfu7lvbrdg2m_c3892ab2-71ee-40f4-be66-4f65c664f568   3h19m</span><br><span class="line">apiserver-bskcrn2i4gf5c5gco6huepssle   apiserver-bskcrn2i4gf5c5gco6huepssle_00e69eb5-4df9-4c3d-87e0-2eb54d7d93c4   3h30m</span><br><span class="line">apiserver-s5dbgrswajhxxnkoaowmosesjm   apiserver-s5dbgrswajhxxnkoaowmosesjm_3665e3ce-dc72-440d-ba7a-ff08f9c71b6a   3h20m</span><br><span class="line">kube-controller-manager                master1_fd5b1081-93e2-4be8-8eb8-8719a70b606a                                3h29m</span><br><span class="line">kube-scheduler                         master1_2b4c98a1-8d8c-4bb3-a3c4-58793022180a                                3h29m</span><br><span class="line">plndr-cp-lock                          master3                                                                     3h20m</span><br><span class="line">plndr-svcs-lock                        master1                                                                     3h20m</span><br></pre></td></tr></table></figure><p><font style="background-color:rgba(255, 255, 255, 0);">集群节点信息查看</font></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@tiaoban k8s]# kubectl get node</span><br><span class="line">NAME      STATUS     ROLES           AGE     VERSION</span><br><span class="line">master1   Ready      control-plane   3h31m   v1.27.6</span><br><span class="line">master2   NotReady   control-plane   3h22m   v1.27.6</span><br><span class="line">master3   Ready      control-plane   3h21m   v1.27.6</span><br><span class="line">work1     Ready      &lt;none&gt;          3h14m   v1.27.6</span><br><span class="line">work2     Ready      &lt;none&gt;          3h14m   v1.27.6</span><br><span class="line">work3     Ready      &lt;none&gt;          3h14m   v1.27.6</span><br></pre></td></tr></table></figure><p><font style="background-color:rgba(255, 255, 255, 0);">业务访问测试</font></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@tiaoban k8s]# curl 192.168.10.150:30380</span><br><span class="line">Hello MyApp | Version: v1 | &lt;a href=&quot;hostname.html&quot;&gt;Pod Name&lt;/a&gt;</span><br></pre></td></tr></table></figure><p><font style="background-color:rgba(255, 255, 255, 0);">结论：当有一个master节点宕机时，VIP会发生漂移，集群各项功能不受影响。</font></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>第一篇文章</title>
      <link href="/2025/03/05/2025-3-5%E7%AC%AC%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0/"/>
      <url>/2025/03/05/2025-3-5%E7%AC%AC%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0/</url>
      
        <content type="html"><![CDATA[<h2 id="这是第一篇文章"><a href="#这是第一篇文章" class="headerlink" title="这是第一篇文章"></a>这是第一篇文章</h2>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
